# 最大token数

文本生成时可生成的最大token数。

输入的token数加上`max_tokens`不能超过模型的最大上下文长度。

大多数模型的上下文长度为2048个token（最新模型支持4096 tokens）